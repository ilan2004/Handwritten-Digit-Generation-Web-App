# Handwritten Digit Generation Web App (CVAE on MNIST)

A simple Streamlit web app to generate handwritten digit images (0–9) using a Conditional Variational Autoencoder (CVAE) trained on the MNIST dataset.

- Backend: PyTorch CVAE (`script.py` defines/trains the model)
- Frontend: Streamlit (`app.py` serves the UI)
- Pretrained weights: `models/cvae_mnist.pth`


## Features
- __Digit-conditioned generation__: pick any digit 0–9 and generate 28×28 grayscale images.
- __Lightweight UI__: quick demo via Streamlit.
- __Reproducible training__: train or retrain the CVAE on MNIST with a single script.


## Quick Start

### 1) Environment
- Python 3.9+ recommended
- Windows, macOS, or Linux

### 2) Install dependencies
```
pip install -r requirements.txt
```
> Note: `torch`/`torchvision` binaries vary by CUDA/CPU. The above line installs CPU builds by default from PyPI. For GPU support, see PyTorch’s install selector: https://pytorch.org/get-started/locally/

### 3) Run the app
```
streamlit run app.py
```
Open the URL that Streamlit prints (typically http://localhost:8501). Select a digit and click "Generate Images" to see 5 samples.


## Project Structure
```
meti/
├─ app.py                 # Streamlit UI to generate images with the trained CVAE
├─ script.py              # CVAE definition and MNIST training script (saves weights)
├─ requirements.txt       # Minimal dependencies for app + training
└─ models/
   └─ cvae_mnist.pth      # Pretrained model weights (generated by script.py)
```


## How it Works
- The CVAE learns to reconstruct MNIST images while conditioning on the digit label.
- At inference, we sample a latent vector `z ~ N(0, I)` and concatenate it with a one-hot label for the chosen digit.
- The decoder generates a 28×28 image consistent with that label.

Model components (see `script.py` and `app.py`):
- `CVAE.encoder`: two Conv2d layers → flatten → Linear
- `CVAE.fc_mu`, `CVAE.fc_logvar`: latent distribution parameters
- `CVAE.reparameterize`: sample `z`
- `CVAE.decoder_input` + `CVAE.decoder`: upsample via Linear → ConvTranspose2d layers to 28×28


## Training (optional)
If you want to (re)train the model and regenerate weights:
```
python script.py
```
This will download MNIST, train for 20 epochs (default), and write `models/cvae_mnist.pth`.

Tips:
- To use GPU, ensure a CUDA-enabled PyTorch install and that `torch.cuda.is_available()` returns True.
- Adjust epochs, batch size, and learning rate inside `script.py` as needed.


## Troubleshooting
- __Torch install issues__: Use the official selector for a matching CUDA/CPU build: https://pytorch.org/get-started/locally/
- __Streamlit not found__: Ensure `pip install -r requirements.txt` ran successfully, and that the correct Python environment is active.
- __Model file missing__: Run `python script.py` to create `models/cvae_mnist.pth` or place your trained weights at that path.


## Roadmap / Ideas
- Add sliders to control latent sampling variance, number of images, and seed.
- Visualize training curves and reconstructions.
- Export generated images as a grid or ZIP.


## License
Add a license file (e.g., MIT) to clarify usage permissions.


## Acknowledgments
- MNIST dataset (Yann LeCun et al.)
- PyTorch and Streamlit communities
